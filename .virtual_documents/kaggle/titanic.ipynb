import pandas as pd 
import numpy as np 



df=pd.read_csv("titanic/train.csv")


df.head(10)


df.shape


df=df.drop('Name', axis=1)
df=df.drop('Ticket', axis=1)
df=df.drop('Cabin', axis=1)


# set 0 for female and 1 for male
df['Sex']=df['Sex'].map({'female':1, 'male':0})



df.head(10)


df['Age'].unique()


df['Age'].isnull().sum()


#fill the null values in the age column to the median of age
df.fillna({'Age' : df['Age'].median()} , inplace=True)


df['Age'].isnull().sum()



# set the age of all children less than one year to 1 year
df.loc[df['Age'] < 1] = 1


df.Age.unique()


#now change the data type of age from float to int
df['Age']=df['Age'].astype(int)



df.Age.value_counts()



df.head()


df['Fare']=df['Fare'].astype(int)


df.head()


df[df['PassengerId']==78]


df.dropna(subset='Embarked', inplace=True)


df['Embarked'].dtype


#drop the records in embarked where value is 1
df = df[df['Embarked'] != 1]



df['Embarked'].unique()


#now change the categorical values in embarked column to s:0 , C:1 and Q:2
df['Embarked']=df['Embarked'].map({'S':0, 'C':1 , 'Q':2})



df['Embarked'].unique()



df.head()


df.isnull().sum()


# normalize features
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])



df.head()


features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']
X = df[features]
y = df['Survived']



# train test split
from sklearn.model_selection import train_test_split
x_train , x_test , y_train , y_test= train_test_split(x,y , test_size=0.2, random_state=22)



'''
n_jobs specifies how many processors (cores) to use.
It is helpful when your dataset is large and you want to speed up the computation (especially during training or prediction).
⚙️ Common Values:
n_jobs=1: Use only one core (default).

n_jobs=4: Use 4 cores.

n_jobs=-1: Use all available cores.
'''
from sklearn.linear_model import LinearRegression
lr= LinearRegression(n_jobs=-1)
lr.fit(x_train , y_train)


y_pred_lr=lr.predict(x_test)


from sklearn.metrics import mean_squared_error , r2_score
print("Linear Regression:")
print("MSE:", mean_squared_error(y_test, y_pred_lr))
print("R² Score:", r2_score(y_test, y_pred_lr))


#using logistic regression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report , accuracy_score
model=LogisticRegression(max_iter=1000)
model.fit(x_train , y_train)

y_pred_log= model.predict(x_test)
print("Accuracy:", accuracy_score(y_test, y_pred_log))
print("Report:\n", classification_report(y_test, y_pred_log))



y_pred_log


test_df=pd.read_csv('titanic/test.csv')
test_df


test_df=test_df.drop('Name', axis=1)
test_df=test_df.drop('Ticket', axis=1)
test_df=test_df.drop('Cabin', axis=1)


# test_df.fillna({'Fare' : test_df['Fare'].median()} , inplace=True)

# test_df['Sex'].isna().sum()
print(test_df.isna().sum())  # Should return 0 for all



test_df.fillna({'Sex' : test_df['Sex'].mode()[0]} , inplace=True)

test_df['Sex']=test_df['Sex'].map({'female':1, 'male':0})
test_df.fillna({'Age' : test_df['Age'].median()} , inplace=True)
test_df.fillna({'Fare' : test_df['Fare'].median()} , inplace=True)
test_df.fillna({'Embarked' : test_df['Embarked'].mode()[0]} , inplace=True)
test_df['Embarked']=test_df['Embarked'].map({'S':0, 'C':1 , 'Q':2})
test_df.loc[test_df['Age'] < 1] = 1
test_df['Fare']=test_df['Fare'].astype(int)
test_df['Age']=test_df['Age'].astype(int)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
test_df[['Age', 'Fare']] = scaler.fit_transform(test_df[['Age', 'Fare']])



print(test_df.isna().sum())  # Should return 0 for all



binary_predictions=model.predict(test_df)


submission = pd.DataFrame({
    "PassengerId": test_df["PassengerId"],
    "Survived": binary_predictions
})


submission.to_csv('submission.csv' , index=False)



